{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import nltk\n",
    "import spacy\n",
    "import imutils\n",
    "from nltk import *\n",
    "import numpy as np\n",
    "import moviepy.editor\n",
    "import es_core_news_sm\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet\n",
    "from spacy.matcher import matcher\n",
    "from spacy.lang.es import Spanish\n",
    "import speech_recognition as sr\n",
    "from moviepy.editor import VideoFileClip\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videoAnalyze(video):\n",
    "    '''\n",
    "    Video-analisis con reconocimiento sobre el género.\n",
    "    '''\n",
    "    with open('../output/model_sequential84.16370153427124.json', 'r') as f:\n",
    "        model_json = json.load(f)\n",
    "\n",
    "    model = model_from_json(model_json)\n",
    "    model.load_weights(\n",
    "        '../output/model_sequential84.16370153427124.h5')\n",
    "\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        '../haarcascade_frontalface_default.xml')\n",
    "\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    result = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        frame = cap.read()[1]\n",
    "\n",
    "        try:\n",
    "            frame = imutils.resize(frame, width=400)\n",
    "            color = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            face = face_cascade.detectMultiScale(\n",
    "                color,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=5\n",
    "            )\n",
    "\n",
    "            frameClone = frame.copy()\n",
    "\n",
    "            if len(face) > 0:\n",
    "                (x, y, w, h) = face[0]\n",
    "                roi = color[y:y+h, x:x+w]\n",
    "                roi = cv2.resize(roi, (60, 60))\n",
    "                roi = np.stack(roi)\n",
    "\n",
    "                p = np.expand_dims(roi, axis=0).reshape(\n",
    "                    np.expand_dims(roi, axis=0).shape[0], 60, 60, 1)\n",
    "\n",
    "                genre = model.predict(p)[0]\n",
    "                label = ['man', 'woman'][np.argmax(genre)]\n",
    "\n",
    "                result.append(label)\n",
    "\n",
    "                if genre.max() > 0.80:\n",
    "                    cv2.rectangle(frameClone, (x, y),\n",
    "                                  (x + w, y + h), (0, 255, 0), 1)\n",
    "                    cv2.putText(frameClone, label, (x, y - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 0), 1)\n",
    "\n",
    "            cv2.imshow('Advertising Analyze',\n",
    "                       imutils.resize(frameClone, width=450))\n",
    "\n",
    "        except:\n",
    "            cap.release()\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    m = result.count('man')\n",
    "    w = result.count('woman')\n",
    "\n",
    "    return print('man -> ', \"{0:.2f}%\".format((m/(m+w))*100), '// woman -> ', \"{0:.2f}%\".format((w/(m+w))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAudio(video):\n",
    "    '''\n",
    "    Transforma el archivo video a un archivo audio, devuelve el audio en formato texto.\n",
    "    '''\n",
    "    vFile = moviepy.editor.VideoFileClip(video)\n",
    "    aFile = vFile.audio\n",
    "\n",
    "    save = f\"{video[:-4]}.wav\"\n",
    "    aFile.write_audiofile(save)\n",
    "\n",
    "    re = sr.Recognizer()\n",
    "\n",
    "    with sr.AudioFile(save) as source:\n",
    "        info_audio = re.record(source)\n",
    "        text = re.recognize_google(info_audio, language='es-ES')\n",
    "\n",
    "    os.remove(save)\n",
    "    print('\\nIMPRIMIENDO AUDIO...')\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTime(video):\n",
    "    '''\n",
    "    Extraer la duración de un video.\n",
    "    '''\n",
    "    clip = VideoFileClip(video)\n",
    "    \n",
    "    return int(clip.duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textSentiment(text):\n",
    "    '''\n",
    "    Realiza un análisis de sentimiento sobre un texto.\n",
    "    '''\n",
    "    s = SentimentIntensityAnalyzer()\n",
    "    result = s.polarity_scores(text)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textAnalysis(text):\n",
    "    '''\n",
    "    Realiza un nálisis textual.\n",
    "    '''\n",
    "    nlp = es_core_news_sm.load()\n",
    "    \n",
    "    complete_doc = nlp(text)\n",
    "    words = [token.text for token in complete_doc if not token.is_stop and not token.is_punct]\n",
    "    \n",
    "    word_freq = Counter(words)\n",
    "    common_words = word_freq.most_common(5)\n",
    "    \n",
    "    nouns = []\n",
    "    adjectives = []\n",
    "    \n",
    "    for token in complete_doc:\n",
    "        print(token,'-', token.tag_, token.pos_)\n",
    "    \n",
    "    for token in complete_doc:\n",
    "        if token.pos_ == 'NOUN':\n",
    "            nouns.append(token)\n",
    "        if token.pos_ == 'ADJ':\n",
    "            adjectives.append(token)\n",
    "            \n",
    "    print('\\nPALABRAS REPETIDAS...')\n",
    "    print(common_words)\n",
    "    print('\\nNOMBRES...')\n",
    "    print(nouns)\n",
    "    print('\\nADJETIVOS...')\n",
    "    print(adjectives)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = '../input/video_prueba1.mpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('VISUALIZANDO SPOT...')\n",
    "print('PORCENTAJES DE REGISTROS POR GÉNERO...')\n",
    "print(videoAnalyze(video), '\\n')\n",
    "print('EXTRAYENDO DURACIÓN DEL SPOT...')\n",
    "print(extractTime(video), 'seg', '\\n')\n",
    "print('EXTRAYENDO AUDIO...')\n",
    "ea = [extractAudio(video)]\n",
    "print(ea, '\\n')\n",
    "print('ANÁLISIS SENTIMENTAL...')\n",
    "print(textSentiment(ea[0]), '\\n')\n",
    "print('ANÁLISIS TEXTUAL...')\n",
    "print(textAnalysis(ea[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
