{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import PIL\n",
    "import IPython\n",
    "import imutils\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/model_sequential84.90231037139893.json','r') as f:\n",
    "    model_json = json.load(f)\n",
    "    \n",
    "model = model_from_json(model_json)\n",
    "\n",
    "model.load_weights('./output/model_sequential84.90231037139893.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = 'video_prueba2.mpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(cam):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_image(a, fmt='jpeg'):\n",
    "    #Create binary stream object\n",
    "    f = BytesIO()\n",
    "\n",
    "    #Convert array to binary stream object\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "\n",
    "    return IPython.display.Image(data=f.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream stopped\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(video)\n",
    "\n",
    "d = IPython.display.display(\"\", display_id=1)\n",
    "d2 = IPython.display.display(\"\", display_id=2)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        t1 = time.time()\n",
    "        frame = get_frame(cam)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        im = array_to_image(frame)\n",
    "\n",
    "        d.update(im)\n",
    "\n",
    "        t2 = time.time()\n",
    "\n",
    "        s = f\"\"\"{int(1/(t2-t1))} FPS\"\"\"\n",
    "        d2.update(IPython.display.HTML(s))\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print()\n",
    "        cam.release()\n",
    "        IPython.display.clear_output()\n",
    "        print (\"Stream stopped\")\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "d = IPython.display.display(\"\", display_id=1)\n",
    "d2 = IPython.display.display(\"\", display_id=2)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        t1 = time.time()\n",
    "        frame = get_frame(cam)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        im = array_to_image(frame)\n",
    "\n",
    "        d.update(im)\n",
    "\n",
    "        t2 = time.time()\n",
    "\n",
    "        s = f\"\"\"{int(1/(t2-t1))} FPS\"\"\"\n",
    "        d2.update( IPython.display.HTML(s))\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print()\n",
    "        cam.release()\n",
    "        IPython.display.clear_output()\n",
    "        print (\"Stream stopped\")\n",
    "        break\n",
    "    \n",
    "    counter=125\n",
    "    if cam.isOpened():\n",
    "        counter+=1\n",
    "        frame = cam.read()[1]\n",
    "        frame = imutils.resize(frame, width=400)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.25, 6)\n",
    "        canvas = np.zeros((300, 300, 3), dtype=\"uint8\") \n",
    "        frameClone = frame.copy()\n",
    "    \n",
    "        if len(faces) > 0:\n",
    "            (fX, fY, fW, fH) = faces[0]\n",
    "            roi = gray[fY:fY + fH, fX:fX + fW]\n",
    "            roi = cv2.resize(roi, (60, 60))\n",
    "            roi = roi/ 255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi, axis=0).reshape(np.expand_dims(roi,axis=0).shape[0], 60, 60, 3)\n",
    "        \n",
    "            cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),\n",
    "                                        (250,128,114), 1)\n",
    "\n",
    "            for (i, (genre, prob)) in enumerate(zip(genre, preds)):\n",
    "                        \n",
    "                        text = \"{}: {:.2f}%\".format(genre, prob * 100)\n",
    "                        w = int(prob * 300)\n",
    "                        cv2.rectangle(canvas, (7, (i * 35) + 5),\n",
    "                        (w, (i * 35) + 35), (250,128,114), -1)\n",
    "                        cv2.putText(canvas, text, (10, (i * 35) + 23),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.45,\n",
    "                        (255,255,255), 2)\n",
    "                        cv2.putText(frameClone, label, (fX, fY - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (250,128,114), 2) \n",
    "            \n",
    "    \n",
    "        numpy_horizontal_concat = np.concatenate((frameClone, canvas), axis=1)\n",
    "        cv2.imshow('Genre', numpy_horizontal_concat)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        counttoclose+=1\n",
    "        print(counttoclose)\n",
    "        if counttoclose == 300:\n",
    "            cap.release()\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    Print('works!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import imutils\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "with open('./output/model_sequential84.90231037139893.json', 'r') as f:\n",
    "    model_json = json.load(f)\n",
    "\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights('./output/model_sequential84.90231037139893.h5')\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = 'video_prueba2.mpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videoAnalyze(video):\n",
    "    route = '/Users/marilomolinacandela/Desktop/' + video\n",
    "\n",
    "    cap = cv2.VideoCapture(route)\n",
    "    while cap.isOpened():\n",
    "        frame = cap.read()[1]\n",
    "\n",
    "        try:\n",
    "            frame = imutils.resize(frame, width=400)\n",
    "            color = cv2.cvtColor(frame, cv2.IMREAD_COLOR)\n",
    "            face = face_cascade.detectMultiScale(\n",
    "                frame,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=5\n",
    "            )\n",
    "\n",
    "            frameClone = frame.copy()\n",
    "\n",
    "            if len(face) > 0:\n",
    "                (x, y, w, h) = face[0]\n",
    "                roi = color[y:y + h, x:x + w]\n",
    "                roi = cv2.resize(roi, (60, 60))\n",
    "                roi = roi / 255.0\n",
    "                roi = img_to_array(roi)\n",
    "                roi = np.expand_dims(roi, axis=0).reshape(\n",
    "                    np.expand_dims(roi, axis=0).shape[0], 60, 60, 3)\n",
    "\n",
    "                genre = model.predict(roi)[0]\n",
    "                label = ['man', 'woman'][genre.argmax()]\n",
    "                print(label)\n",
    "\n",
    "                cv2.rectangle(frameClone, (x, y),\n",
    "                              (x + w, y + h), (250, 128, 114), 1)\n",
    "                #cv2.putText(frameClone, label, (x, y - 10))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            cap.release()\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return 'Works!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VideoCapture 0x1414e9390>\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "woman\n",
      "'NoneType' object has no attribute 'shape'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Works!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoAnalyze(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = './video_prueba1.mpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import moviepy.editor\n",
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "def extractAudio(video):\n",
    "    vFile = moviepy.editor.VideoFileClip(video)\n",
    "    aFile = vFile.audio\n",
    "\n",
    "    save = f\"{video[:-4]}.wav\"\n",
    "    aFile.write_audiofile(save)\n",
    "\n",
    "    re = sr.Recognizer()\n",
    "\n",
    "    with sr.AudioFile(save) as source:\n",
    "        info_audio = re.record(source)\n",
    "        text = re.recognize_google(info_audio, language='es-ES')\n",
    "        \n",
    "    os.remove(save)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  34%|███▍      | 153/446 [00:00<00:00, 1517.96it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in ./video_prueba1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mírate preparada para comerte el día y cuidándote con Alpro avena 100% vegetal bien hecho con deliciosa buena fuente de calcio y fibra sin nada de azúcar y por supuesto sin edulcorantes un poco más porque no Alpro 100% vegetal bien hecho'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractAudio('./video_prueba1.mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function AudioFileClip.__del__ at 0x13cbe74d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/moviepy/audio/io/AudioFileClip.py\", line 94, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/moviepy/audio/io/AudioFileClip.py\", line 89, in close\n",
      "    if self.reader:\n",
      "AttributeError: 'AudioFileClip' object has no attribute 'reader'\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "def textAnalyze(text):\n",
    "    '''\n",
    "    Realiza un análisis de sentimiento sobre un texto.\n",
    "    '''\n",
    "    s = SentimentIntensityAnalyzer()\n",
    "    result = s.polarity_scores(text)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.207, 'neu': 0.793, 'pos': 0.0, 'compound': -0.8555}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textAnalyze('mírate preparada para comerte el día y cuidándote con Alpro avena 100% vegetal bien hecho con deliciosa buena fuente de calcio y fibra sin nada de azúcar y por supuesto sin edulcorantes un poco más porque no Alpro 100% vegetal bien hecho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Para las palabras\n",
    "Las palabras de detención son las palabras más comunes en un idioma. En el idioma Inglés, algunos ejemplos de \n",
    "palabras vacías son the, are, but, y they. La mayoría de las oraciones deben contener palabras de detención para \n",
    "ser oraciones completas que tengan sentido.\n",
    "\n",
    "En general, las palabras de detención se eliminan porque no son significativas y distorsionan el análisis de \n",
    "frecuencia de palabras. spaCy tiene una lista de palabras de parada para el idioma inglés:\n",
    "\n",
    ">>> import spacy\n",
    ">>> spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    ">>> len(spacy_stopwords)\n",
    "326\n",
    ">>> for stop_word in list(spacy_stopwords)[:10]:\n",
    "...     print(stop_word)\n",
    "...\n",
    "using\n",
    "becomes\n",
    "had\n",
    "itself\n",
    "once\n",
    "often\n",
    "is\n",
    "herein\n",
    "who\n",
    "too\n",
    "Puede eliminar palabras de detención del texto de entrada:\n",
    "\n",
    ">>> for token in about_doc:\n",
    "...     if not token.is_stop:\n",
    "...         print (token)\n",
    "...\n",
    "Gus\n",
    "Proto\n",
    "Python\n",
    "developer\n",
    "currently\n",
    "working\n",
    "London\n",
    "-\n",
    "based\n",
    "Fintech\n",
    "company\n",
    ".\n",
    "interested\n",
    "learning\n",
    "Natural\n",
    "Language\n",
    "Processing\n",
    ".\n",
    "Palabras vacías gusta is, a, for, the, y inno se imprimen en la salida anterior. También puede crear una lista de \n",
    "tokens que no contengan palabras de detención:\n",
    "\n",
    ">>> about_no_stopword_doc = [token for token in about_doc if not token.is_stop]\n",
    ">>> print (about_no_stopword_doc)\n",
    "[Gus, Proto, Python, developer, currently, working, London,\n",
    "-, based, Fintech, company, ., interested, learning, Natural,\n",
    "Language, Processing, .]\n",
    "about_no_stopword_doc se pueden unir con espacios para formar una oración sin palabras de detención."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frecuencia de palabras\n",
    "Ahora puede convertir un texto dado en tokens y realizar un análisis estadístico sobre él. Este análisis puede \n",
    "brindarle varias ideas sobre patrones de palabras, como palabras comunes o palabras únicas en el texto:\n",
    "\n",
    ">>> from collections import Counter\n",
    ">>> complete_text = ('Gus Proto is a Python developer currently'\n",
    "...     'working for a London-based Fintech company. He is'\n",
    "...     ' interested in learning Natural Language Processing.'\n",
    "...     ' There is a developer conference happening on 21 July'\n",
    "...     ' 2019 in London. It is titled \"Applications of Natural'\n",
    "...     ' Language Processing\". There is a helpline number '\n",
    "...     ' available at +1-1234567891. Gus is helping organize it.'\n",
    "...     ' He keeps organizing local Python meetups and several'\n",
    "...     ' internal talks at his workplace. Gus is also presenting'\n",
    "...     ' a talk. The talk will introduce the reader about \"Use'\n",
    "...     ' cases of Natural Language Processing in Fintech\".'\n",
    "...     ' Apart from his work, he is very passionate about music.'\n",
    "...     ' Gus is learning to play the Piano. He has enrolled '\n",
    "...     ' himself in the weekend batch of Great Piano Academy.'\n",
    "...     ' Great Piano Academy is situated in Mayfair or the City'\n",
    "...     ' of London and has world-class piano instructors.')\n",
    "...\n",
    ">>> complete_doc = nlp(complete_text)\n",
    ">>> # Remove stop words and punctuation symbols\n",
    ">>> words = [token.text for token in complete_doc\n",
    "...          if not token.is_stop and not token.is_punct]\n",
    ">>> word_freq = Counter(words)\n",
    ">>> # 5 commonly occurring words with their frequencies\n",
    ">>> common_words = word_freq.most_common(5)\n",
    ">>> print (common_words)\n",
    "[('Gus', 4), ('London', 3), ('Natural', 3), ('Language', 3), ('Processing', 3)]\n",
    ">>> # Unique words\n",
    ">>> unique_words = [word for (word, freq) in word_freq.items() if freq == 1]\n",
    ">>> print (unique_words)\n",
    "['Proto', 'currently', 'working', 'based', 'company',\n",
    "'interested', 'conference', 'happening', '21', 'July',\n",
    "'2019', 'titled', 'Applications', 'helpline', 'number',\n",
    "'available', '+1', '1234567891', 'helping', 'organize',\n",
    "'keeps', 'organizing', 'local', 'meetups', 'internal',\n",
    "'talks', 'workplace', 'presenting', 'introduce', 'reader',\n",
    "'Use', 'cases', 'Apart', 'work', 'passionate', 'music', 'play',\n",
    "'enrolled', 'weekend', 'batch', 'situated', 'Mayfair', 'City',\n",
    "'world', 'class', 'piano', 'instructors']\n",
    "Al observar las palabras comunes, se puede ver que el texto en su conjunto es probablemente alrededor Gus, \n",
    "Londono Natural Language Processing. De esta manera, puede tomar cualquier texto no estructurado y realizar \n",
    "análisis estadísticos para saber de qué se trata.\n",
    "\n",
    "Aquí hay otro ejemplo del mismo texto con palabras de detención:\n",
    "\n",
    ">>> words_all = [token.text for token in complete_doc if not token.is_punct]\n",
    ">>> word_freq_all = Counter(words_all)\n",
    ">>> # 5 commonly occurring words with their frequencies\n",
    ">>> common_words_all = word_freq_all.most_common(5)\n",
    ">>> print (common_words_all)\n",
    "[('is', 10), ('a', 5), ('in', 5), ('Gus', 4), ('of', 4)]\n",
    "Cuatro de cada cinco de las palabras más comunes son palabras vacías, que no le dicen mucho sobre el texto. \n",
    "Si considera detener las palabras mientras realiza el análisis de la frecuencia de las palabras, no podrá obtener \n",
    "información significativa del texto de entrada. Por eso es tan importante eliminar las palabras de detención."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parte del etiquetado de voz\n",
    "Parte del discurso o POS es una función gramatical que explica cómo se usa una palabra en particular en una oración. \n",
    "Hay ocho partes del discurso:\n",
    "\n",
    "Sustantivo\n",
    "Pronombre\n",
    "Adjetivo\n",
    "Verbo\n",
    "Adverbio\n",
    "Preposición\n",
    "Conjunción\n",
    "Interjección\n",
    "Parte del etiquetado de voz es el proceso de asignar una etiqueta POS a cada token, dependiendo de su uso en la \n",
    "oración. Las etiquetas POS son útiles para asignar una categoría sintáctica como sustantivo o verbo a cada palabra.\n",
    "\n",
    "En spaCy, las etiquetas POS están disponibles como un atributo en el Tokenobjeto:\n",
    "\n",
    ">>> for token in about_doc:\n",
    "...     print (token, token.tag_, token.pos_, spacy.explain(token.tag_))\n",
    "...\n",
    "Gus NNP PROPN noun, proper singular\n",
    "Proto NNP PROPN noun, proper singular\n",
    "is VBZ VERB verb, 3rd person singular present\n",
    "a DT DET determiner\n",
    "Python NNP PROPN noun, proper singular\n",
    "developer NN NOUN noun, singular or mass\n",
    "currently RB ADV adverb\n",
    "working VBG VERB verb, gerund or present participle\n",
    "for IN ADP conjunction, subordinating or preposition\n",
    "a DT DET determiner\n",
    "London NNP PROPN noun, proper singular\n",
    "- HYPH PUNCT punctuation mark, hyphen\n",
    "based VBN VERB verb, past participle\n",
    "Fintech NNP PROPN noun, proper singular\n",
    "company NN NOUN noun, singular or mass\n",
    ". . PUNCT punctuation mark, sentence closer\n",
    "He PRP PRON pronoun, personal\n",
    "is VBZ VERB verb, 3rd person singular present\n",
    "interested JJ ADJ adjective\n",
    "in IN ADP conjunction, subordinating or preposition\n",
    "learning VBG VERB verb, gerund or present participle\n",
    "Natural NNP PROPN noun, proper singular\n",
    "Language NNP PROPN noun, proper singular\n",
    "Processing NNP PROPN noun, proper singular\n",
    ". . PUNCT punctuation mark, sentence closer\n",
    "Aquí, Tokense accede a dos atributos de la clase:\n",
    "\n",
    "tag_ enumera la parte fina del discurso.\n",
    "pos_ enumera la parte del discurso de grano grueso.\n",
    "spacy.explainda detalles descriptivos sobre una etiqueta POS particular. spaCy proporciona una lista completa de \n",
    "etiquetas junto con una explicación para cada etiqueta.\n",
    "\n",
    "Usando etiquetas POS, puede extraer una categoría particular de palabras:\n",
    "\n",
    ">>> nouns = []\n",
    ">>> adjectives = []\n",
    ">>> for token in about_doc:\n",
    "...     if token.pos_ == 'NOUN':\n",
    "...         nouns.append(token)\n",
    "...     if token.pos_ == 'ADJ':\n",
    "...         adjectives.append(token)\n",
    "...\n",
    ">>> nouns\n",
    "[developer, company]\n",
    ">>> adjectives\n",
    "[interested]\n",
    "Puede usar esto para obtener información, eliminar los sustantivos más comunes o ver qué adjetivos se usan para \n",
    "un sustantivo en particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coincidencia basada en reglas usando spaCy\n",
    "La coincidencia basada en reglas es uno de los pasos para extraer información de texto no estructurado. Se utiliza \n",
    "para identificar y extraer tokens y frases de acuerdo con patrones (como minúsculas) y características gramaticales \n",
    "(como parte del discurso).\n",
    "\n",
    "La coincidencia basada en reglas puede usar expresiones regulares para extraer entidades (como números de teléfono) \n",
    "de un texto no estructurado. Es diferente de extraer texto usando expresiones regulares solo en el sentido de que \n",
    "las expresiones regulares no consideran los atributos léxicos y gramaticales del texto.\n",
    "\n",
    "Con la coincidencia basada en reglas, puede extraer un nombre y un apellido, que siempre son nombres propios :\n",
    "\n",
    ">>> from spacy.matcher import Matcher\n",
    ">>> matcher = Matcher(nlp.vocab)\n",
    ">>> def extract_full_name(nlp_doc):\n",
    "...     pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "...     matcher.add('FULL_NAME', None, pattern)\n",
    "...     matches = matcher(nlp_doc)\n",
    "...     for match_id, start, end in matches:\n",
    "...         span = nlp_doc[start:end]\n",
    "...         return span.text\n",
    "...\n",
    ">>> extract_full_name(about_doc)\n",
    "'Gus Proto'\n",
    "En este ejemplo, patternhay una lista de objetos que define la combinación de tokens que deben coincidir. Ambas \n",
    "etiquetas POS son PROPN(nombre propio). Por lo tanto, patternconsta de dos objetos en los que deberían estar las \n",
    "etiquetas POS para ambos tokens PROPN. Este patrón se agrega al Matcheruso FULL_NAMEy el match_id. Finalmente, \n",
    "las coincidencias se obtienen con sus índices iniciales y finales.\n",
    "\n",
    "También puede usar la coincidencia basada en reglas para extraer números de teléfono:\n",
    "\n",
    ">>> from spacy.matcher import Matcher\n",
    ">>> matcher = Matcher(nlp.vocab)\n",
    ">>> conference_org_text = ('There is a developer conference'\n",
    "...     'happening on 21 July 2019 in London. It is titled'\n",
    "...     ' \"Applications of Natural Language Processing\".'\n",
    "...     ' There is a helpline number available'\n",
    "...     ' at (123) 456-789')\n",
    "...\n",
    ">>> def extract_phone_number(nlp_doc):\n",
    "...     pattern = [{'ORTH': '('}, {'SHAPE': 'ddd'},\n",
    "...                {'ORTH': ')'}, {'SHAPE': 'ddd'},\n",
    "...                {'ORTH': '-', 'OP': '?'},\n",
    "...                {'SHAPE': 'ddd'}]\n",
    "...     matcher.add('PHONE_NUMBER', None, pattern)\n",
    "...     matches = matcher(nlp_doc)\n",
    "...     for match_id, start, end in matches:\n",
    "...         span = nlp_doc[start:end]\n",
    "...         return span.text\n",
    "...\n",
    ">>> conference_org_doc = nlp(conference_org_text)\n",
    ">>> extract_phone_number(conference_org_doc)\n",
    "'(123) 456-789'\n",
    "En este ejemplo, solo se actualiza el patrón para que coincida con los números de teléfono del ejemplo anterior. \n",
    "Aquí, también se usan algunos atributos del token:\n",
    "\n",
    "ORTH da el texto exacto del token.\n",
    "SHAPE transforma la cadena de token para mostrar características ortográficas.\n",
    "OPdefine operadores. Usar ?como valor significa que el patrón es opcional, lo que significa que puede coincidir 0 \n",
    "o 1 veces.\n",
    "Nota: Por razones de simplicidad, los números de teléfono se supone que son de un formato en particular: (123) \n",
    "        456-789. Puede cambiar esto dependiendo de su caso de uso.\n",
    "\n",
    "La coincidencia basada en reglas le ayuda a identificar y extraer tokens y frases de acuerdo con patrones léxicos \n",
    "(como minúsculas) y características gramaticales (como parte del discurso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
